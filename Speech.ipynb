{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech.ipynb",
      "provenance": [],
      "mount_file_id": "1ZwDDyIlKtysn0upUmM9h0qz1O6Bm0t9c",
      "authorship_tag": "ABX9TyN9cP+3IhW06VkJjpUwLJHC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aishvellappally/Speech-Encoder/blob/master/Speech.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VE6qId3jwBuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from ast import literal_eval"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gUeH6ywSP61",
        "colab_type": "code",
        "outputId": "75f78950-fc02-4492-b5cc-6ddb46d36bca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import sys\n",
        "if 'google.colab' in sys.modules: # Colab-only Tensorflow version selector\n",
        "  %tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BANU08LBSVKz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, accuracy_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import spacy \n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras.models import Model,Sequential\n",
        "import tensorflow.keras.layers\n",
        "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, MaxPooling1D, Conv1D, Flatten, Activation\n",
        "from tensorflow.keras.layers import Bidirectional, GRU, BatchNormalization, GlobalAveragePooling1D\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, Callback, ReduceLROnPlateau\n",
        "import tensorflow.keras.callbacks\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRjW3YQjSNuP",
        "colab_type": "code",
        "outputId": "72b68480-0823-48a9-f51c-689c533e1500",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        }
      },
      "source": [
        "# Detect hardware, return appropriate distribution strategy\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "    print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "    tpu = None\n",
        "    gpus = tf.config.experimental.list_logical_devices(\"GPU\")\n",
        "\n",
        "if tpu:\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
        "elif len(gpus) > 1: # multiple GPUs in one VM\n",
        "    strategy = tf.distribute.MirroredStrategy(gpus)\n",
        "    print('multi-gpu')\n",
        "else: # default strategy that works on CPU and single GPU\n",
        "    strategy = tf.distribute.get_strategy()\n",
        "    print('cpu')\n",
        "\n",
        "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on TPU  ['10.119.189.138:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.119.189.138:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.119.189.138:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "REPLICAS:  8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHmnzrAS4Abd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "roKIIW3kc8Sf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_excel('data_new.xlsx', delimiter = '\\t')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Idqf3WrJiAO",
        "colab_type": "code",
        "outputId": "9a67959f-211c-4659-e0e0-dd120458115f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>actor</th>\n",
              "      <th>gender</th>\n",
              "      <th>emotion</th>\n",
              "      <th>valence</th>\n",
              "      <th>activation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>speech_files/Ses01F_impro01/Ses01F_impro01_F00...</td>\n",
              "      <td>F01</td>\n",
              "      <td>F</td>\n",
              "      <td>neu</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>speech_files/Ses01M_impro03/Ses01M_impro03_F02...</td>\n",
              "      <td>F01</td>\n",
              "      <td>F</td>\n",
              "      <td>neu</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>speech_files/Ses01M_impro03/Ses01M_impro03_F02...</td>\n",
              "      <td>F01</td>\n",
              "      <td>F</td>\n",
              "      <td>exc</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>speech_files/Ses01M_impro03/Ses01M_impro03_F01...</td>\n",
              "      <td>F01</td>\n",
              "      <td>F</td>\n",
              "      <td>exc</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>speech_files/Ses01M_impro03/Ses01M_impro03_F01...</td>\n",
              "      <td>F01</td>\n",
              "      <td>F</td>\n",
              "      <td>neu</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                path actor  ... valence activation\n",
              "0  speech_files/Ses01F_impro01/Ses01F_impro01_F00...   F01  ...       0          0\n",
              "1  speech_files/Ses01M_impro03/Ses01M_impro03_F02...   F01  ...       2          1\n",
              "2  speech_files/Ses01M_impro03/Ses01M_impro03_F02...   F01  ...       2          1\n",
              "3  speech_files/Ses01M_impro03/Ses01M_impro03_F01...   F01  ...       2          2\n",
              "4  speech_files/Ses01M_impro03/Ses01M_impro03_F01...   F01  ...       2          0\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07x4LHQVQLTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.drop(['MFB', 'normalized'], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErYdJp4sQr_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data=data.drop(['Unnamed: 0'],axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhPR-o7qDzIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data.replace(['low','mid','high'], [0,1,2], inplace = True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcUHzMqI5Kwn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(20):\n",
        "  if (i == 0):\n",
        "    feat1_df = pd.read_pickle('drive/My Drive/feature_files/feature_orig%s.pkl'%(i+1))\n",
        "    result = feat1_df\n",
        "  else:\n",
        "    feat_df = pd.read_pickle('drive/My Drive/feature_files/feature_orig%s.pkl'%(i+1))\n",
        "    frames = [result,feat_df]\n",
        "    result = pd.concat(frames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjRzZ7A9PfGY",
        "colab_type": "code",
        "outputId": "3a806807-5c79-4e9f-9536-70e669403591",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "result.describe"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.describe of 0        [[0.00033833986, 0.00013587401, 2.0531057e-05,...\n",
              "1        [[0.011469948, 0.015378022, 0.029045707, 0.003...\n",
              "2        [[0.010275147, 0.07941946, 0.020318927, 0.0062...\n",
              "3        [[0.0006920437, 0.0022492136, 0.0011821993, 0....\n",
              "4        [[0.0019367585, 0.0015250507, 0.00030263982, 8...\n",
              "                               ...                        \n",
              "10034    [[0.0023372732, 0.00034015003, 4.03764e-05, 2....\n",
              "10035    [[0.00050546747, 0.00029521994, 0.0001469691, ...\n",
              "10036    [[0.0064669014, 0.0015277971, 0.0006420764, 0....\n",
              "10037    [[0.0025848665, 0.0013115586, 0.0007592481, 0....\n",
              "10038    [[0.010716233, 0.0026280445, 0.004199538, 0.00...\n",
              "Name: MFB, Length: 10039, dtype: object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGH0RY_iRRNj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['features']=result"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PmdQfObRafc",
        "colab_type": "code",
        "outputId": "5db5be04-cb78-4d2b-86a6-cccfe7b320ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "data.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>actor</th>\n",
              "      <th>gender</th>\n",
              "      <th>emotion</th>\n",
              "      <th>valence</th>\n",
              "      <th>activation</th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>speech_files/Ses01F_impro01/Ses01F_impro01_F00...</td>\n",
              "      <td>F01</td>\n",
              "      <td>F</td>\n",
              "      <td>neu</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0.00033833986, 0.00013587401, 2.0531057e-05,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>speech_files/Ses01M_impro03/Ses01M_impro03_F02...</td>\n",
              "      <td>F01</td>\n",
              "      <td>F</td>\n",
              "      <td>neu</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>[[0.011469948, 0.015378022, 0.029045707, 0.003...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>speech_files/Ses01M_impro03/Ses01M_impro03_F02...</td>\n",
              "      <td>F01</td>\n",
              "      <td>F</td>\n",
              "      <td>exc</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>[[0.010275147, 0.07941946, 0.020318927, 0.0062...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>speech_files/Ses01M_impro03/Ses01M_impro03_F01...</td>\n",
              "      <td>F01</td>\n",
              "      <td>F</td>\n",
              "      <td>exc</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>[[0.0006920437, 0.0022492136, 0.0011821993, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>speech_files/Ses01M_impro03/Ses01M_impro03_F01...</td>\n",
              "      <td>F01</td>\n",
              "      <td>F</td>\n",
              "      <td>neu</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0.0019367585, 0.0015250507, 0.00030263982, 8...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                path  ...                                           features\n",
              "0  speech_files/Ses01F_impro01/Ses01F_impro01_F00...  ...  [[0.00033833986, 0.00013587401, 2.0531057e-05,...\n",
              "1  speech_files/Ses01M_impro03/Ses01M_impro03_F02...  ...  [[0.011469948, 0.015378022, 0.029045707, 0.003...\n",
              "2  speech_files/Ses01M_impro03/Ses01M_impro03_F02...  ...  [[0.010275147, 0.07941946, 0.020318927, 0.0062...\n",
              "3  speech_files/Ses01M_impro03/Ses01M_impro03_F01...  ...  [[0.0006920437, 0.0022492136, 0.0011821993, 0....\n",
              "4  speech_files/Ses01M_impro03/Ses01M_impro03_F01...  ...  [[0.0019367585, 0.0015250507, 0.00030263982, 8...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jchWnpKOar3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train _ val _ test split\n",
        "actor_group = data.groupby('actor')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFA1emGwfI7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_actors = actor_group.size()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfByXSkyfrlW",
        "colab_type": "code",
        "outputId": "2e866e9b-4c62-4717-cf89-590ceb418be4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "num_actors"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "actor\n",
              "F01     873\n",
              "F02     859\n",
              "F03    1048\n",
              "F04     987\n",
              "F05    1033\n",
              "M01     946\n",
              "M02     952\n",
              "M03    1088\n",
              "M04    1116\n",
              "M05    1137\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5uIWJxoftIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#training for emotion classifier\n",
        "df_train = data[0:3767]\n",
        "df_train= df_train.append(data[4800:8902]) #training data has F01-F04, M01-M04"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQZ6YMmXaVuG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = df_train.reset_index(drop = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiO0AecBuVzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train_shuff = shuffle(df_train, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ddu2IuUdHjhI",
        "colab_type": "code",
        "outputId": "0db14013-9421-4cb4-82af-08e386c589ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        }
      },
      "source": [
        "df_train_shuff"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>path</th>\n",
              "      <th>actor</th>\n",
              "      <th>gender</th>\n",
              "      <th>emotion</th>\n",
              "      <th>valence</th>\n",
              "      <th>activation</th>\n",
              "      <th>features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7794</th>\n",
              "      <td>speech_files/Ses04M_script02_1/Ses04M_script02...</td>\n",
              "      <td>M04</td>\n",
              "      <td>M</td>\n",
              "      <td>exc</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>[[4.996508e-05, 9.925534e-05, 0.00020741053, 3...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>speech_files/Ses01M_script01_1/Ses01M_script01...</td>\n",
              "      <td>F01</td>\n",
              "      <td>F</td>\n",
              "      <td>ang</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>[[0.022402408, 0.05171589, 0.003449829, 0.0059...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6496</th>\n",
              "      <td>speech_files/Ses03M_impro05a/Ses03M_impro05a_M...</td>\n",
              "      <td>M03</td>\n",
              "      <td>M</td>\n",
              "      <td>xxx</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>[[0.0012744386, 0.00063978403, 0.00023430413, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5046</th>\n",
              "      <td>speech_files/Ses02M_impro03/Ses02M_impro03_M01...</td>\n",
              "      <td>M02</td>\n",
              "      <td>M</td>\n",
              "      <td>hap</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>[[0.00022389139, 0.00086323667, 0.00044364342,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2298</th>\n",
              "      <td>speech_files/Ses03F_impro08/Ses03F_impro08_F02...</td>\n",
              "      <td>F03</td>\n",
              "      <td>F</td>\n",
              "      <td>neu</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[[1.9750947e-05, 4.2786047e-05, 3.9290302e-05,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5226</th>\n",
              "      <td>speech_files/Ses02M_script03_2/Ses02M_script03...</td>\n",
              "      <td>M02</td>\n",
              "      <td>M</td>\n",
              "      <td>fru</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[[0.00019274857, 0.00051902473, 0.00026156593,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5390</th>\n",
              "      <td>speech_files/Ses02M_script03_2/Ses02M_script03...</td>\n",
              "      <td>M02</td>\n",
              "      <td>M</td>\n",
              "      <td>fru</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0.0012090846, 0.018292079, 0.0060115145, 0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>speech_files/Ses01F_script02_1/Ses01F_script02...</td>\n",
              "      <td>F01</td>\n",
              "      <td>F</td>\n",
              "      <td>hap</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0.00023642181, 0.0013219569, 0.006506602, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7603</th>\n",
              "      <td>speech_files/Ses04M_script02_1/Ses04M_script02...</td>\n",
              "      <td>M04</td>\n",
              "      <td>M</td>\n",
              "      <td>xxx</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0.00046033465, 0.0001907555, 0.00014631843, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7270</th>\n",
              "      <td>speech_files/Ses04F_impro01/Ses04F_impro01_M01...</td>\n",
              "      <td>M04</td>\n",
              "      <td>M</td>\n",
              "      <td>fru</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[[0.00025565422, 9.030236e-05, 0.00017342875, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7869 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   path  ...                                           features\n",
              "7794  speech_files/Ses04M_script02_1/Ses04M_script02...  ...  [[4.996508e-05, 9.925534e-05, 0.00020741053, 3...\n",
              "503   speech_files/Ses01M_script01_1/Ses01M_script01...  ...  [[0.022402408, 0.05171589, 0.003449829, 0.0059...\n",
              "6496  speech_files/Ses03M_impro05a/Ses03M_impro05a_M...  ...  [[0.0012744386, 0.00063978403, 0.00023430413, ...\n",
              "5046  speech_files/Ses02M_impro03/Ses02M_impro03_M01...  ...  [[0.00022389139, 0.00086323667, 0.00044364342,...\n",
              "2298  speech_files/Ses03F_impro08/Ses03F_impro08_F02...  ...  [[1.9750947e-05, 4.2786047e-05, 3.9290302e-05,...\n",
              "...                                                 ...  ...                                                ...\n",
              "5226  speech_files/Ses02M_script03_2/Ses02M_script03...  ...  [[0.00019274857, 0.00051902473, 0.00026156593,...\n",
              "5390  speech_files/Ses02M_script03_2/Ses02M_script03...  ...  [[0.0012090846, 0.018292079, 0.0060115145, 0.0...\n",
              "860   speech_files/Ses01F_script02_1/Ses01F_script02...  ...  [[0.00023642181, 0.0013219569, 0.006506602, 0....\n",
              "7603  speech_files/Ses04M_script02_1/Ses04M_script02...  ...  [[0.00046033465, 0.0001907555, 0.00014631843, ...\n",
              "7270  speech_files/Ses04F_impro01/Ses04F_impro01_M01...  ...  [[0.00025565422, 9.030236e-05, 0.00017342875, ...\n",
              "\n",
              "[7869 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNns0vqgubYR",
        "colab_type": "code",
        "outputId": "57275cc4-2a72-4b90-d0dd-9e8834aa186c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "np.unique(df_train_shuff['actor'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['F01', 'F02', 'F03', 'F04', 'M01', 'M02', 'M03', 'M04'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vukGLGZNtRrM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = df_train_shuff['features']\n",
        "y1_train = df_train_shuff['valence']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zU9SJ8CdXv4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJjeHZRjWPnq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhXnMW4PqL8C",
        "colab_type": "code",
        "outputId": "7cabd015-8b84-44da-d12b-ec7ac53f4e2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "X_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.02623276, -0.02607872, -0.02126434, ..., -0.01462094,\n",
              "        -0.01472081, -0.01477564],\n",
              "       [-0.02124226, -0.02528837, -0.02446065, ..., -0.01672508,\n",
              "        -0.01680934, -0.01696464],\n",
              "       [-0.01355734, -0.02132892, -0.02665111, ..., -0.00751508,\n",
              "        -0.00750138, -0.00749504],\n",
              "       ...,\n",
              "       [-0.07252279, -0.01447601, -0.00268523, ..., -0.00141627,\n",
              "        -0.00140561, -0.0013989 ],\n",
              "       [-0.04708572, -0.01443674, -0.00221898, ..., -0.0012806 ,\n",
              "        -0.00127166, -0.00126816],\n",
              "       [-0.03291224, -0.01301061, -0.00263509, ..., -0.00091918,\n",
              "        -0.00090958, -0.00091048]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWeX2EDhVFjs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_test = data[['features','valence']][8902:10039] #test set has M05\n",
        "df_test = df_test.reset_index(drop=True)\n",
        "df_test = shuffle(df_test, random_state =42)\n",
        "X_test= df_test['features']\n",
        "y1_test=df_test['valence']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLOSL2tDqXvz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = X_test.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt2p5AVAV7Pe",
        "colab_type": "code",
        "outputId": "6f9246df-255f-4627-abf8-cb6b058e04c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "y1_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "787     0\n",
              "903     0\n",
              "289     2\n",
              "1083    2\n",
              "332     0\n",
              "       ..\n",
              "1044    0\n",
              "1095    2\n",
              "1130    0\n",
              "860     1\n",
              "1126    0\n",
              "Name: valence, Length: 1137, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gS8pJeRBXBFd",
        "colab_type": "code",
        "outputId": "b3ad5a2d-e28e-4cdf-e2b7-7dacfd6196b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "df_val = data[['features','valence']][3767:4800] #validation set has F05\n",
        "df_val = df_val.reset_index(drop=True)\n",
        "df_val=shuffle(df_val, random_state=42)\n",
        "X_val = df_val['features']\n",
        "y1_val = df_val['valence']\n",
        "y1_val"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "294    0\n",
              "453    2\n",
              "636    2\n",
              "139    2\n",
              "538    0\n",
              "      ..\n",
              "87     2\n",
              "330    0\n",
              "466    0\n",
              "121    1\n",
              "860    2\n",
              "Name: valence, Length: 1033, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF5f7cZYqcIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val = X_val.to_numpy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRoyFXpYXDST",
        "colab_type": "code",
        "outputId": "a18c6362-bbd0-44ed-85e8-09800fc8142a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.unique(data['actor'][3767:4800])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['F05'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-f1AvnuCAb1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_weights_val = {0: 1,\n",
        "                1: 3.4,\n",
        "                2: 1.9}\n",
        "class_weights_act = {0: 1.2,\n",
        "                1: 1.3,\n",
        "                2: 1}               "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VA1dRkLOXQvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 3\n",
        "def onehot(arr, num_class):\n",
        "    return np.eye(num_class)[np.array(arr.astype(int)).reshape(-1)]\n",
        "\n",
        "y1_train = onehot(y1_train, num_classes)\n",
        "y1_test = onehot(y1_test, num_classes)\n",
        "y1_val = onehot(y1_val, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wf7FcGXIHTOt",
        "colab_type": "code",
        "outputId": "486946ae-049b-4360-c957-e7b6100cf922",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "y1_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TkoRJzPpX-6e",
        "colab_type": "code",
        "outputId": "6aa2f01a-48b3-4704-8dc7-3ec1d6538a8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "y1_val"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       ...,\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Jp4nnYnYBZz",
        "colab_type": "code",
        "outputId": "7d576ed1-c247-4ec3-83ad-d65f0ab507b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "y1_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       ...,\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iymo-6a8aKGF",
        "colab_type": "code",
        "outputId": "7ae8e7cb-ec25-4ddd-d42e-54dc737bb86c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X_val"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([array([[ 0.16402997, -0.2695424 ,  0.01268109, ..., -0.16402731,\n",
              "        -0.18561003, -0.19890452],\n",
              "       [ 0.00971331, -0.36207599, -0.30403992, ..., -0.00063711,\n",
              "        -0.22234832, -0.28126085],\n",
              "       [-0.02932763,  0.15023624, -0.26153386, ..., -0.07441207,\n",
              "        -0.06020063, -0.33874527],\n",
              "       ...,\n",
              "       [-0.26220268, -0.26194294, -0.26401869, ..., -0.25484433,\n",
              "        -0.25539139, -0.25931294],\n",
              "       [-0.26218938, -0.26242416, -0.26413846, ..., -0.25509589,\n",
              "        -0.25535502, -0.25913832],\n",
              "       [-0.25995967, -0.26034942, -0.26194085, ..., -0.25329317,\n",
              "        -0.25356814, -0.25753554]]),\n",
              "       array([[ 0.15689507, -0.17972679, -0.48543388, ..., -0.03328354,\n",
              "        -0.15412313, -0.34637862],\n",
              "       [-0.07359037, -0.51767366, -0.48750263, ..., -0.13120751,\n",
              "        -0.07303078, -0.21899575],\n",
              "       [-0.71153698, -0.85893272, -0.3018456 , ..., -0.15359658,\n",
              "        -0.35168574, -0.19486316],\n",
              "       ...,\n",
              "       [ 0.73249597,  0.74005499,  0.7984309 , ...,  0.66194313,\n",
              "         0.67181157,  0.69210551],\n",
              "       [ 0.650852  ,  0.71902257,  0.79660894, ...,  0.67811788,\n",
              "         0.66676274,  0.69161178],\n",
              "       [ 0.66820577,  0.66582918,  0.7980491 , ...,  0.67461535,\n",
              "         0.68086581,  0.69214353]]),\n",
              "       array([[ 0.41919366,  0.04780564, -0.33415314, ...,  0.11833238,\n",
              "         0.03465683, -0.39094678],\n",
              "       [ 0.29100279, -0.05204902, -0.36939999, ...,  0.457871  ,\n",
              "         0.38295975,  0.0770425 ],\n",
              "       [ 0.07290453, -0.23355452, -0.10600963, ...,  0.51273004,\n",
              "         0.636412  ,  0.31189063],\n",
              "       ...,\n",
              "       [-0.26220268, -0.26194294, -0.26401869, ..., -0.25484433,\n",
              "        -0.25539139, -0.25931294],\n",
              "       [-0.26218938, -0.26242416, -0.26413846, ..., -0.25509589,\n",
              "        -0.25535502, -0.25913832],\n",
              "       [-0.25995967, -0.26034942, -0.26194085, ..., -0.25329317,\n",
              "        -0.25356814, -0.25753554]]),\n",
              "       ...,\n",
              "       array([[ 0.40984865,  0.07177812,  0.06187228, ..., -0.2351779 ,\n",
              "        -0.26346969, -0.11357804],\n",
              "       [ 0.3897066 ,  0.20050157, -0.50232996, ..., -0.21450691,\n",
              "        -0.1026706 , -0.34015791],\n",
              "       [ 0.09763514, -0.42610693, -0.00595411, ..., -0.01878541,\n",
              "        -0.18497373, -0.34647696],\n",
              "       ...,\n",
              "       [-0.26220268, -0.26194294, -0.26401869, ..., -0.25484433,\n",
              "        -0.25539139, -0.25931294],\n",
              "       [-0.26218938, -0.26242416, -0.26413846, ..., -0.25509589,\n",
              "        -0.25535502, -0.25913832],\n",
              "       [-0.25995967, -0.26034942, -0.26194085, ..., -0.25329317,\n",
              "        -0.25356814, -0.25753554]]),\n",
              "       array([[-0.52652416,  0.52131216,  0.20384603, ...,  0.73647981,\n",
              "         0.66283482,  0.28577684],\n",
              "       [ 0.06882382,  0.65831153,  0.68638214, ...,  0.6550143 ,\n",
              "         0.50299985,  0.14702312],\n",
              "       [-0.31223837,  0.77789371,  0.70214598, ...,  0.59685299,\n",
              "         0.58890403,  0.40283743],\n",
              "       ...,\n",
              "       [-0.26220268, -0.26194294, -0.26401869, ..., -0.25484433,\n",
              "        -0.25539139, -0.25931294],\n",
              "       [-0.26218938, -0.26242416, -0.26413846, ..., -0.25509589,\n",
              "        -0.25535502, -0.25913832],\n",
              "       [-0.25995967, -0.26034942, -0.26194085, ..., -0.25329317,\n",
              "        -0.25356814, -0.25753554]]),\n",
              "       array([[-0.56315042,  0.14966684, -0.16691673, ...,  0.31620571,\n",
              "         0.14569605, -0.17174832],\n",
              "       [ 0.47048829,  0.23248273, -0.21981973, ...,  0.33240254,\n",
              "         0.22192304,  0.09999156],\n",
              "       [ 0.30659326, -0.05214   , -0.01477908, ...,  0.32697721,\n",
              "         0.32043104, -0.09335112],\n",
              "       ...,\n",
              "       [-0.26220268, -0.26194294, -0.26401869, ..., -0.25484433,\n",
              "        -0.25539139, -0.25931294],\n",
              "       [-0.26218938, -0.26242416, -0.26413846, ..., -0.25509589,\n",
              "        -0.25535502, -0.25913832],\n",
              "       [-0.25995967, -0.26034942, -0.26194085, ..., -0.25329317,\n",
              "        -0.25356814, -0.25753554]])], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLtH5qRQuWXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1_train = np.zeros((X_train.shape[0],909,40))\n",
        "for i in range(X_train.shape[0]):\n",
        "  for j in range(909):\n",
        "      X1_train[i][j][0:40]=X_train[i][j][0:40]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RogqPH4bZLTl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1_val = np.zeros((X_val.shape[0],909,40))\n",
        "for i in range(X_val.shape[0]):\n",
        "  for j in range(909):\n",
        "      X1_val[i][j][0:40]=X_val[i][j][0:40]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Zzu5XLvKAlQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X1_test = np.zeros((X_test.shape[0],909,40))\n",
        "for i in range(X_test.shape[0]):\n",
        "  for j in range(909):\n",
        "      X1_test[i][j][0:40]=X_test[i][j][0:40]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjX0Xc11trpR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model():\n",
        "  nb_filter = [128,128,128,64,64]\n",
        "  filter_length = [2,2,2,2,2]\n",
        "  pool_length = 2\n",
        "  in_frames = Input(shape=(448,40), dtype='float')\n",
        "  \n",
        "  embedded = Conv1D(filters=128,kernel_size=2,padding='same',activation='relu',kernel_initializer='glorot_normal',\n",
        "                    strides=1)(in_frames)\n",
        "  embedded = MaxPooling1D(pool_size=pool_length)(embedded)\n",
        "  embedded = Dropout(0.2)(embedded)\n",
        "  embedded = Conv1D(filters=128,kernel_size=2,padding='same',activation='relu',kernel_initializer='glorot_normal',\n",
        "                    strides=1)(embedded)\n",
        "  embedded = MaxPooling1D(pool_size=pool_length)(embedded)\n",
        "  embedded = Dropout(0.2)(embedded)\n",
        "  embedded = Conv1D(filters=128,kernel_size=2,padding='same',activation='relu',kernel_initializer='glorot_normal',\n",
        "                    strides=1)(embedded)\n",
        "  embedded = MaxPooling1D(pool_size=pool_length)(embedded)\n",
        "  embedded = Dropout(0.2)(embedded)\n",
        "  embedded = Conv1D(filters=128,kernel_size=2,padding='same',activation='relu',kernel_initializer='glorot_normal',\n",
        "                    strides=1)(embedded)\n",
        "  embedded = MaxPooling1D(pool_size=pool_length)(embedded)\n",
        "  embedded = Dropout(0.2)(embedded)\n",
        "  embedded = Conv1D(filters=128,kernel_size=2,padding='same',activation='relu',kernel_initializer='glorot_normal',\n",
        "                    strides=1)(embedded)\n",
        "  embedded = MaxPooling1D(pool_size=pool_length)(embedded)\n",
        "  embedded = Dropout(0.2)(embedded)\n",
        "    \n",
        "   \n",
        "  b_gru_1 = Bidirectional(GRU(64, return_sequences=False, dropout=0.2, recurrent_dropout=0.2, implementation=0))(embedded)\n",
        "  #b_gru_2 = Bidirectional(GRU(32, return_sequences=False, dropout=0.2, recurrent_dropout=0.2, implementation=0))(b_gru_1)\n",
        "\n",
        "  output = Dropout(0.2)(b_gru_1)\n",
        "  output = Dense(3, activation='softmax')(output)\n",
        "\n",
        "  model = Model(inputs=in_frames, outputs=output)\n",
        "\n",
        "  model.summary()\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['ACCURACY',UAR])\n",
        "  return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVnTfs-Hmkmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import backend as K\n",
        "def UAR(y_true, y_pred):\n",
        "  TP = [0,0,0]\n",
        "  FN = [0,0,0]\n",
        "  for i in range(y_true.shape[0]):\n",
        "    if (y_true[i][0]==1):\n",
        "      if (y_pred[i][0]>=0.5):\n",
        "        TP[0]+=1\n",
        "      else:\n",
        "        FN[0]+=1\n",
        "    elif (y_true[i][1]==1):\n",
        "      if (y_pred[i][1]>=0.5):\n",
        "        TP[1]+=1\n",
        "      else:\n",
        "        FN[1]+=1\n",
        "    else:\n",
        "      if (y_pred[i][2]>=0.5):\n",
        "        TP[2]+=1\n",
        "      else:\n",
        "        FN[2]+=1\n",
        "  R1 = TP[0]/(TP[0]+FN[0])\n",
        "  R2 = TP[1]/(TP[1]+FN[1])\n",
        "  R3 = TP[2]/(TP[2]+FN[2])\n",
        "  avg_recall = 1/3* (R1+R2+R3)\n",
        "  return R1, R2, R3, avg_recall"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uuVFTttSHyz",
        "colab_type": "code",
        "outputId": "7e744afe-8d35-46e0-9d96-ce843709b25f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "with strategy.scope():\n",
        "  model = Sequential()\n",
        "  model.add(Input(shape=(909,40),dtype='float'))\n",
        "  model.add(Conv1D(128, 2, padding='causal',input_shape=(909,40), use_bias=True, kernel_initializer='lecun_normal',\n",
        "                   kernel_regularizer = l2(1e-6)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('selu'))\n",
        "  model.add(MaxPooling1D(2))\n",
        "  model.add(Conv1D(128, 2, padding='causal', use_bias=True, kernel_initializer='lecun_normal',\n",
        "                   kernel_regularizer = l2(1e-6)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('selu'))\n",
        "  model.add(MaxPooling1D(2))\n",
        "  model.add(Conv1D(64, 2, padding='causal', use_bias=True, kernel_initializer='lecun_normal',\n",
        "                   kernel_regularizer = l2(1e-6)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('selu'))\n",
        "  model.add(MaxPooling1D(2))\n",
        "  model.add(Conv1D(64, 2, padding='causal', use_bias=True, kernel_initializer='lecun_normal',\n",
        "                   kernel_regularizer = l2(1e-6)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('selu'))\n",
        "  model.add(MaxPooling1D(2))\n",
        "  model.add(Conv1D(64, 2, padding='causal', use_bias=True, kernel_initializer='lecun_normal',\n",
        "                   kernel_regularizer = l2(1e-6)))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('selu'))\n",
        "  model.add(MaxPooling1D(2))\n",
        "  model.add(Bidirectional(GRU(64, return_sequences=True, recurrent_dropout=0.2, dropout = 0.2, implementation=2, \n",
        "                              use_bias=True,kernel_regularizer=l2(1e-6),recurrent_regularizer = l2(1e-6))))\n",
        "  model.add(Bidirectional(GRU(64, return_sequences=True, recurrent_dropout=0.2, dropout = 0.2, implementation=2, \n",
        "                              use_bias=True,kernel_regularizer=l2(1e-6),recurrent_regularizer = l2(1e-6))))\n",
        "  model.add(GlobalAveragePooling1D())\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(3))\n",
        "  model.add(Activation('softmax'))\n",
        "  opt = RMSprop(momentum=0.9)\n",
        "  model.summary()\n",
        "  model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv1d_20 (Conv1D)           (None, 909, 128)          10368     \n",
            "_________________________________________________________________\n",
            "batch_normalization_24 (Batc (None, 909, 128)          512       \n",
            "_________________________________________________________________\n",
            "activation_24 (Activation)   (None, 909, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_20 (MaxPooling (None, 454, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_21 (Conv1D)           (None, 454, 128)          32896     \n",
            "_________________________________________________________________\n",
            "batch_normalization_25 (Batc (None, 454, 128)          512       \n",
            "_________________________________________________________________\n",
            "activation_25 (Activation)   (None, 454, 128)          0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_21 (MaxPooling (None, 227, 128)          0         \n",
            "_________________________________________________________________\n",
            "conv1d_22 (Conv1D)           (None, 227, 64)           16448     \n",
            "_________________________________________________________________\n",
            "batch_normalization_26 (Batc (None, 227, 64)           256       \n",
            "_________________________________________________________________\n",
            "activation_26 (Activation)   (None, 227, 64)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_22 (MaxPooling (None, 113, 64)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_23 (Conv1D)           (None, 113, 64)           8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_27 (Batc (None, 113, 64)           256       \n",
            "_________________________________________________________________\n",
            "activation_27 (Activation)   (None, 113, 64)           0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_23 (MaxPooling (None, 56, 64)            0         \n",
            "_________________________________________________________________\n",
            "conv1d_24 (Conv1D)           (None, 56, 64)            8256      \n",
            "_________________________________________________________________\n",
            "batch_normalization_28 (Batc (None, 56, 64)            256       \n",
            "_________________________________________________________________\n",
            "activation_28 (Activation)   (None, 56, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_24 (MaxPooling (None, 28, 64)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_8 (Bidirection (None, 28, 128)           49920     \n",
            "_________________________________________________________________\n",
            "bidirectional_9 (Bidirection (None, 28, 128)           74496     \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_4 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_29 (Batc (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 3)                 387       \n",
            "_________________________________________________________________\n",
            "activation_29 (Activation)   (None, 3)                 0         \n",
            "=================================================================\n",
            "Total params: 203,331\n",
            "Trainable params: 202,179\n",
            "Non-trainable params: 1,152\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knBfZAmDnVDX",
        "colab_type": "code",
        "outputId": "29163860-a1be-4669-f76a-a500d3194bf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS=50\n",
        "BATCH_SIZE = 128\n",
        "rlop = ReduceLROnPlateau(monitor='val_loss',factor=0.5,patience=5)\n",
        "checkpoint = ModelCheckpoint(\"model.h5\", monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "#early = EarlyStopping(monitor='val_loss', mode='min')\n",
        "callback = [checkpoint]\n",
        "#10-fold cross validation\n",
        "\n",
        "history = model.fit(X1_train, y1_train, epochs = EPOCHS, batch_size= BATCH_SIZE, validation_data=(X1_val, y1_val),verbose = 1,class_weight=class_weights_val, callbacks = [callback,rlop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.9267 - accuracy: 0.3617\n",
            "Epoch 00001: val_loss improved from inf to 1.03992, saving model to model.h5\n",
            "62/62 [==============================] - 12s 192ms/step - loss: 1.9267 - accuracy: 0.3617 - val_loss: 1.0399 - val_accuracy: 0.3814 - lr: 0.0010\n",
            "Epoch 2/50\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.8615 - accuracy: 0.3522\n",
            "Epoch 00002: val_loss improved from 1.03992 to 0.93803, saving model to model.h5\n",
            "62/62 [==============================] - 4s 67ms/step - loss: 1.8631 - accuracy: 0.3535 - val_loss: 0.9380 - val_accuracy: 0.5924 - lr: 0.0010\n",
            "Epoch 3/50\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.8357 - accuracy: 0.3473\n",
            "Epoch 00003: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 60ms/step - loss: 1.8357 - accuracy: 0.3473 - val_loss: 1.0306 - val_accuracy: 0.5779 - lr: 0.0010\n",
            "Epoch 4/50\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.8399 - accuracy: 0.3486\n",
            "Epoch 00004: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 60ms/step - loss: 1.8415 - accuracy: 0.3479 - val_loss: 1.0886 - val_accuracy: 0.4840 - lr: 0.0010\n",
            "Epoch 5/50\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.7855 - accuracy: 0.3492\n",
            "Epoch 00005: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 59ms/step - loss: 1.7890 - accuracy: 0.3485 - val_loss: 1.1557 - val_accuracy: 0.2459 - lr: 0.0010\n",
            "Epoch 6/50\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.7838 - accuracy: 0.3530\n",
            "Epoch 00006: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 60ms/step - loss: 1.7838 - accuracy: 0.3530 - val_loss: 1.1451 - val_accuracy: 0.1946 - lr: 0.0010\n",
            "Epoch 7/50\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.7726 - accuracy: 0.3733\n",
            "Epoch 00007: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 59ms/step - loss: 1.7739 - accuracy: 0.3712 - val_loss: 1.0546 - val_accuracy: 0.4627 - lr: 0.0010\n",
            "Epoch 8/50\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.7780 - accuracy: 0.3673\n",
            "Epoch 00008: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 57ms/step - loss: 1.7772 - accuracy: 0.3666 - val_loss: 1.2233 - val_accuracy: 0.2459 - lr: 5.0000e-04\n",
            "Epoch 9/50\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.7739 - accuracy: 0.3687\n",
            "Epoch 00009: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 58ms/step - loss: 1.7739 - accuracy: 0.3687 - val_loss: 1.1008 - val_accuracy: 0.3369 - lr: 5.0000e-04\n",
            "Epoch 10/50\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.7640 - accuracy: 0.3753\n",
            "Epoch 00010: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 57ms/step - loss: 1.7640 - accuracy: 0.3753 - val_loss: 1.3740 - val_accuracy: 0.1830 - lr: 5.0000e-04\n",
            "Epoch 11/50\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.7794 - accuracy: 0.3797\n",
            "Epoch 00011: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 58ms/step - loss: 1.7794 - accuracy: 0.3797 - val_loss: 1.1082 - val_accuracy: 0.2623 - lr: 5.0000e-04\n",
            "Epoch 12/50\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.7599 - accuracy: 0.3824\n",
            "Epoch 00012: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 58ms/step - loss: 1.7606 - accuracy: 0.3840 - val_loss: 1.0636 - val_accuracy: 0.5682 - lr: 5.0000e-04\n",
            "Epoch 13/50\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.7404 - accuracy: 0.4013\n",
            "Epoch 00013: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 58ms/step - loss: 1.7395 - accuracy: 0.4032 - val_loss: 1.0499 - val_accuracy: 0.5140 - lr: 2.5000e-04\n",
            "Epoch 14/50\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.7349 - accuracy: 0.4048\n",
            "Epoch 00014: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 58ms/step - loss: 1.7350 - accuracy: 0.4048 - val_loss: 1.0587 - val_accuracy: 0.4589 - lr: 2.5000e-04\n",
            "Epoch 15/50\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.7321 - accuracy: 0.3994\n",
            "Epoch 00015: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 59ms/step - loss: 1.7321 - accuracy: 0.3994 - val_loss: 1.0333 - val_accuracy: 0.5808 - lr: 2.5000e-04\n",
            "Epoch 16/50\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.7304 - accuracy: 0.4114\n",
            "Epoch 00016: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 59ms/step - loss: 1.7312 - accuracy: 0.4111 - val_loss: 1.0707 - val_accuracy: 0.3011 - lr: 2.5000e-04\n",
            "Epoch 17/50\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.7276 - accuracy: 0.4060\n",
            "Epoch 00017: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 58ms/step - loss: 1.7276 - accuracy: 0.4060 - val_loss: 1.1244 - val_accuracy: 0.2527 - lr: 2.5000e-04\n",
            "Epoch 18/50\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.7252 - accuracy: 0.4034\n",
            "Epoch 00018: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 59ms/step - loss: 1.7246 - accuracy: 0.4031 - val_loss: 1.0873 - val_accuracy: 0.2604 - lr: 1.2500e-04\n",
            "Epoch 19/50\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.7123 - accuracy: 0.4129\n",
            "Epoch 00019: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 59ms/step - loss: 1.7112 - accuracy: 0.4124 - val_loss: 1.0876 - val_accuracy: 0.2633 - lr: 1.2500e-04\n",
            "Epoch 20/50\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.7187 - accuracy: 0.4054\n",
            "Epoch 00020: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 57ms/step - loss: 1.7182 - accuracy: 0.4058 - val_loss: 1.1018 - val_accuracy: 0.2507 - lr: 1.2500e-04\n",
            "Epoch 21/50\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.7128 - accuracy: 0.4078\n",
            "Epoch 00021: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 58ms/step - loss: 1.7128 - accuracy: 0.4081 - val_loss: 1.0488 - val_accuracy: 0.5344 - lr: 1.2500e-04\n",
            "Epoch 22/50\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.7070 - accuracy: 0.4269\n",
            "Epoch 00022: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 59ms/step - loss: 1.7063 - accuracy: 0.4274 - val_loss: 1.0707 - val_accuracy: 0.4046 - lr: 1.2500e-04\n",
            "Epoch 23/50\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.7026 - accuracy: 0.4229\n",
            "Epoch 00023: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 58ms/step - loss: 1.7013 - accuracy: 0.4236 - val_loss: 1.0661 - val_accuracy: 0.3766 - lr: 6.2500e-05\n",
            "Epoch 24/50\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.7080 - accuracy: 0.4027\n",
            "Epoch 00024: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 71ms/step - loss: 1.7055 - accuracy: 0.4031 - val_loss: 1.0621 - val_accuracy: 0.3475 - lr: 6.2500e-05\n",
            "Epoch 25/50\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.6929 - accuracy: 0.4167\n",
            "Epoch 00025: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 59ms/step - loss: 1.6929 - accuracy: 0.4167 - val_loss: 1.0480 - val_accuracy: 0.5198 - lr: 6.2500e-05\n",
            "Epoch 26/50\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.6962 - accuracy: 0.4274\n",
            "Epoch 00026: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 58ms/step - loss: 1.6962 - accuracy: 0.4274 - val_loss: 1.0393 - val_accuracy: 0.5518 - lr: 6.2500e-05\n",
            "Epoch 27/50\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.6993 - accuracy: 0.4271\n",
            "Epoch 00027: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 60ms/step - loss: 1.6993 - accuracy: 0.4256 - val_loss: 1.0607 - val_accuracy: 0.3166 - lr: 6.2500e-05\n",
            "Epoch 28/50\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.6929 - accuracy: 0.4324\n",
            "Epoch 00028: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 59ms/step - loss: 1.6940 - accuracy: 0.4327 - val_loss: 1.0412 - val_accuracy: 0.5266 - lr: 3.1250e-05\n",
            "Epoch 29/50\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.6970 - accuracy: 0.4275\n",
            "Epoch 00029: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 58ms/step - loss: 1.6978 - accuracy: 0.4283 - val_loss: 1.0653 - val_accuracy: 0.3185 - lr: 3.1250e-05\n",
            "Epoch 30/50\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.6876 - accuracy: 0.4301\n",
            "Epoch 00030: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 60ms/step - loss: 1.6897 - accuracy: 0.4298 - val_loss: 1.0595 - val_accuracy: 0.3253 - lr: 3.1250e-05\n",
            "Epoch 31/50\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.6858 - accuracy: 0.4337\n",
            "Epoch 00031: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 59ms/step - loss: 1.6887 - accuracy: 0.4332 - val_loss: 1.0583 - val_accuracy: 0.3282 - lr: 3.1250e-05\n",
            "Epoch 32/50\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.6906 - accuracy: 0.4235\n",
            "Epoch 00032: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 57ms/step - loss: 1.6895 - accuracy: 0.4234 - val_loss: 1.0554 - val_accuracy: 0.3359 - lr: 3.1250e-05\n",
            "Epoch 33/50\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.6888 - accuracy: 0.4392\n",
            "Epoch 00033: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 59ms/step - loss: 1.6888 - accuracy: 0.4392 - val_loss: 1.0629 - val_accuracy: 0.3330 - lr: 1.5625e-05\n",
            "Epoch 34/50\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.6877 - accuracy: 0.4385\n",
            "Epoch 00034: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 57ms/step - loss: 1.6852 - accuracy: 0.4389 - val_loss: 1.0681 - val_accuracy: 0.3243 - lr: 1.5625e-05\n",
            "Epoch 35/50\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.6953 - accuracy: 0.4341\n",
            "Epoch 00035: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 58ms/step - loss: 1.6928 - accuracy: 0.4342 - val_loss: 1.0629 - val_accuracy: 0.3243 - lr: 1.5625e-05\n",
            "Epoch 36/50\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.6856 - accuracy: 0.4381\n",
            "Epoch 00036: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 59ms/step - loss: 1.6846 - accuracy: 0.4386 - val_loss: 1.0597 - val_accuracy: 0.3320 - lr: 1.5625e-05\n",
            "Epoch 37/50\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.6882 - accuracy: 0.4360\n",
            "Epoch 00037: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 58ms/step - loss: 1.6879 - accuracy: 0.4360 - val_loss: 1.0644 - val_accuracy: 0.3311 - lr: 1.5625e-05\n",
            "Epoch 38/50\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.6825 - accuracy: 0.4382\n",
            "Epoch 00038: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 58ms/step - loss: 1.6851 - accuracy: 0.4377 - val_loss: 1.0605 - val_accuracy: 0.3379 - lr: 7.8125e-06\n",
            "Epoch 39/50\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.6904 - accuracy: 0.4369\n",
            "Epoch 00039: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 61ms/step - loss: 1.6904 - accuracy: 0.4369 - val_loss: 1.0587 - val_accuracy: 0.3330 - lr: 7.8125e-06\n",
            "Epoch 40/50\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.6845 - accuracy: 0.4310\n",
            "Epoch 00040: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 59ms/step - loss: 1.6872 - accuracy: 0.4294 - val_loss: 1.0606 - val_accuracy: 0.3320 - lr: 7.8125e-06\n",
            "Epoch 41/50\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.6808 - accuracy: 0.4378\n",
            "Epoch 00041: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 58ms/step - loss: 1.6808 - accuracy: 0.4378 - val_loss: 1.0608 - val_accuracy: 0.3291 - lr: 7.8125e-06\n",
            "Epoch 42/50\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.6885 - accuracy: 0.4383\n",
            "Epoch 00042: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 58ms/step - loss: 1.6880 - accuracy: 0.4379 - val_loss: 1.0552 - val_accuracy: 0.3572 - lr: 7.8125e-06\n",
            "Epoch 43/50\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.6821 - accuracy: 0.4434\n",
            "Epoch 00043: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 59ms/step - loss: 1.6821 - accuracy: 0.4434 - val_loss: 1.0596 - val_accuracy: 0.3630 - lr: 3.9063e-06\n",
            "Epoch 44/50\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.6785 - accuracy: 0.4365\n",
            "Epoch 00044: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 59ms/step - loss: 1.6797 - accuracy: 0.4365 - val_loss: 1.0596 - val_accuracy: 0.3475 - lr: 3.9063e-06\n",
            "Epoch 45/50\n",
            "60/62 [============================>.] - ETA: 0s - loss: 1.6898 - accuracy: 0.4401\n",
            "Epoch 00045: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 59ms/step - loss: 1.6876 - accuracy: 0.4405 - val_loss: 1.0563 - val_accuracy: 0.3524 - lr: 3.9063e-06\n",
            "Epoch 46/50\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.6816 - accuracy: 0.4404\n",
            "Epoch 00046: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 60ms/step - loss: 1.6804 - accuracy: 0.4405 - val_loss: 1.0557 - val_accuracy: 0.3417 - lr: 3.9063e-06\n",
            "Epoch 47/50\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.6819 - accuracy: 0.4410\n",
            "Epoch 00047: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 59ms/step - loss: 1.6824 - accuracy: 0.4419 - val_loss: 1.0570 - val_accuracy: 0.3437 - lr: 3.9063e-06\n",
            "Epoch 48/50\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.6825 - accuracy: 0.4308\n",
            "Epoch 00048: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 58ms/step - loss: 1.6825 - accuracy: 0.4308 - val_loss: 1.0567 - val_accuracy: 0.3427 - lr: 1.9531e-06\n",
            "Epoch 49/50\n",
            "61/62 [============================>.] - ETA: 0s - loss: 1.6858 - accuracy: 0.4361\n",
            "Epoch 00049: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 59ms/step - loss: 1.6861 - accuracy: 0.4359 - val_loss: 1.0577 - val_accuracy: 0.3349 - lr: 1.9531e-06\n",
            "Epoch 50/50\n",
            "62/62 [==============================] - ETA: 0s - loss: 1.6819 - accuracy: 0.4407\n",
            "Epoch 00050: val_loss did not improve from 0.93803\n",
            "62/62 [==============================] - 4s 58ms/step - loss: 1.6819 - accuracy: 0.4407 - val_loss: 1.0571 - val_accuracy: 0.3398 - lr: 1.9531e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q0_KTmrmaEBt",
        "colab_type": "code",
        "outputId": "68b3e45c-d0c3-4377-8fbe-e92ca780f00a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model train vs validation loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_R9Zhs6jGKn",
        "colab_type": "code",
        "outputId": "a313c9b4-8137-4faf-db31-147f9a84c690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions = model.predict(X1_test, batch_size = 128, verbose = 1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 1s 99ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcT2WhkhLftM",
        "colab_type": "code",
        "outputId": "80c756dc-8483-4ab6-bcd0-42b63924ff45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predictions.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1144, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1LSTcoduoawa",
        "colab_type": "code",
        "outputId": "46f8a1cb-5bdf-4a67-ea9d-00c25fd3e18b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y1_test.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1137, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFyQYz5RjRVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "R1, R2, R3, recall = UAR(y1_test, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F76ZyH7uN50",
        "colab_type": "code",
        "outputId": "3bd36814-ee4b-4527-b50d-fd3744d70d40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "recall"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07159524105496509"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0iQvqhICj1G",
        "colab_type": "code",
        "outputId": "fb192b8a-9f2a-4b0b-9737-e5ddfc24e261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "R1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1875"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6P3ZdBdClug",
        "colab_type": "code",
        "outputId": "6c130205-f186-499e-f42c-039a5b7847bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "R2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.005780346820809248"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05TOw7t7CnyN",
        "colab_type": "code",
        "outputId": "d3d84662-390e-47c6-dcf9-b970cb44a99c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "R3"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.021505376344086023"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    }
  ]
}